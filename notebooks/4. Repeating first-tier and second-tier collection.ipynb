{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e51a01",
   "metadata": {},
   "source": [
    "# 0. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c91c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load the autoreload extension to automatically reload modules before executing code (to avoid restarting the kernel)\n",
    "%load_ext autoreload \n",
    "\n",
    "# Enable autoreload for all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc80c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom functions\n",
    "from resources.github_functions import GithubScraper\n",
    "from resources.filter_functions import filter_ties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa9faa",
   "metadata": {},
   "source": [
    "## 0.1 File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928a4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "import resources.filepaths as fp\n",
    "\n",
    "fp_main = fp.fp_main\n",
    "fp_main_output = fp.fp_main_output\n",
    "\n",
    "# To output data that has to go to external s-drive\n",
    "fp_main_external = fp.fp_main_external\n",
    "fp_output_external = fp.fp_output_external"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132ead0",
   "metadata": {},
   "source": [
    "# 1. Load in the second tier company list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98214df7",
   "metadata": {},
   "source": [
    "## 1.2 Processing the company list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da7c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial list of companies\n",
    "second_tier_companies = pd.read_csv(\n",
    "    fp_main_output / 'second_tier_companies.csv'\n",
    ")\n",
    "\n",
    "# Subset relevant company info for initial list\n",
    "list_of_company_info = second_tier_companies[\n",
    "    ['company_search_keyword', 'company_category', 'without_location_filter', 'company_label_name']\n",
    "]\n",
    "\n",
    "# Create company category map for initial list\n",
    "company_category_map = dict(zip(\n",
    "    list_of_company_info['company_search_keyword'],\n",
    "    list_of_company_info['company_category']\n",
    "))\n",
    "\n",
    "# Output company category map\n",
    "with open(fp_main_output / 'company_category_map.jsonl', 'a', encoding='utf-8') as f:\n",
    "    for keyword, category in company_category_map.items():\n",
    "        f.write(json.dumps({'company_search_keyword': keyword, 'company_category': category}, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4afb1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip object to loop through, when querying companies.\n",
    "company_location_filter_bool_zip = zip(\n",
    "    list_of_company_info['company_search_keyword'],\n",
    "    list_of_company_info['without_location_filter'],\n",
    "    list_of_company_info['company_label_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d236999",
   "metadata": {},
   "source": [
    "# 2. Repeating the queriyng of second-tier company names and scraping users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b8970",
   "metadata": {},
   "source": [
    "## 2.1 Loading in scrapelogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e440b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User log exists: first_tier_user_scrapelog.jsonl\n",
      "[INFO] Company log exists: company_scrapelog.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Collecting users already scraped\n",
    "users_already_scraped = set()\n",
    "companies_already_scraped = set()\n",
    "\n",
    "user_log_file_name = 'first_tier_user_scrapelog.jsonl'\n",
    "company_log_file_name = 'company_scrapelog.jsonl'\n",
    "user_log_path = fp_output_external / user_log_file_name\n",
    "company_log_path = fp_main_output / company_log_file_name\n",
    "\n",
    "# Ensure files exist and print message\n",
    "if user_log_path.exists():\n",
    "    print(f\"[INFO] User log exists: {user_log_path.name}\")\n",
    "else:\n",
    "    user_log_path.touch(exist_ok=True)\n",
    "\n",
    "if company_log_path.exists():\n",
    "    print(f\"[INFO] Company log exists: {company_log_path.name}\")\n",
    "else:\n",
    "    company_log_path.touch(exist_ok=True)\n",
    "\n",
    "# Read user log\n",
    "with open(user_log_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            user_info = json.loads(line)\n",
    "            users_already_scraped.add(user_info['user_login'])\n",
    "        except (json.JSONDecodeError, KeyError) as err:\n",
    "            print(f\"[WARNING] Skipping malformed user line: {err}\")\n",
    "\n",
    "# Read company log\n",
    "with open(company_log_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            company = json.loads(line)\n",
    "            companies_already_scraped.add(company['company_name'])\n",
    "        except (json.JSONDecodeError, KeyError) as err:\n",
    "            print(f\"[WARNING] Skipping malformed company line: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf059d",
   "metadata": {},
   "source": [
    "## 2.2 Instantiating the GithubScraper and scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad1a7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GithubScraper initialized with 21 companies and 68 users already scraped.\n",
      "GitHub REST API ratelimit reset time for token is 2025-08-12 15:41:28. That will be in a little less than 34 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scraping users for company: knowit\n",
      "[NEW] GitHub ratelimit threshold set to 300 (max rate: 5000)\n",
      "[INFO] Scraping user: miracle-as\n",
      "[NEW] GitHub ratelimit threshold set to 5 (max rate: 30)\n",
      "[NEW] GitHub ratelimit threshold set to 300 (max rate: 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m gs\u001b[38;5;241m.\u001b[39musers_already_scraped\u001b[38;5;241m.\u001b[39madd(named_user\u001b[38;5;241m.\u001b[39mlogin)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 3.3.2 Get user info (may return None if repo limit exceeded or no match)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m user_row \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamed_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip user if they don't meet scraping criteria\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:122\u001b[0m, in \u001b[0;36mratelimiter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Reset time passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(wait_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms ago, skipping sleep.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:698\u001b[0m, in \u001b[0;36mGithubScraper.get_user_info\u001b[0;34m(self, user, company_label, company_filter)\u001b[0m\n\u001b[1;32m    693\u001b[0m inferred_company \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28mlist\u001b[39m(matched_company_strings\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mif\u001b[39;00m matched_company_strings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    695\u001b[0m )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# 4. Connections\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m follows_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_follows_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m follows_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_follows_out(user)\n\u001b[1;32m    700\u001b[0m watches_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_watches_in(all_repos, user)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:122\u001b[0m, in \u001b[0;36mratelimiter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Reset time passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(wait_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms ago, skipping sleep.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:321\u001b[0m, in \u001b[0;36mGithubScraper.get_follows_in\u001b[0;34m(self, user)\u001b[0m\n\u001b[1;32m    318\u001b[0m follows_in \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     follows_in\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 321\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepo_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mowner_login\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfollower\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_followers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    329\u001b[0m     )\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m follows_in\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:325\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m follows_in \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     follows_in\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m    321\u001b[0m         [\n\u001b[1;32m    322\u001b[0m             {\n\u001b[1;32m    323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mowner_login\u001b[39m\u001b[38;5;124m\"\u001b[39m: follower\u001b[38;5;241m.\u001b[39mlogin,\n\u001b[0;32m--> 325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfollower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;241m.\u001b[39misoformat(),\n\u001b[1;32m    326\u001b[0m             }\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m follower \u001b[38;5;129;01min\u001b[39;00m user\u001b[38;5;241m.\u001b[39mget_followers()\n\u001b[1;32m    328\u001b[0m         ]\n\u001b[1;32m    329\u001b[0m     )\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m follows_in\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/NamedUser.py:203\u001b[0m, in \u001b[0;36mNamedUser.created_at\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreated_at\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m datetime:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_completeIfNotSet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_created_at\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_at\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/GithubObject.py:543\u001b[0m, in \u001b[0;36mCompletableGithubObject._completeIfNotSet\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completeIfNotSet\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Attribute) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, _NotSetType):\n\u001b[0;32m--> 543\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_completeIfNeeded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/GithubObject.py:547\u001b[0m, in \u001b[0;36mCompletableGithubObject._completeIfNeeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completeIfNeeded\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__completed:\n\u001b[0;32m--> 547\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/GithubObject.py:552\u001b[0m, in \u001b[0;36mCompletableGithubObject.__complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompletableObject(\u001b[38;5;241m400\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot complete object as it contains no URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 552\u001b[0m headers, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJsonAndCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__completeHeaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storeAndUseAttributes(headers, data)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:625\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input, follow_302_redirect)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequestJsonAndCheck\u001b[39m(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    608\u001b[0m     verb: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     follow_302_redirect: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    Send a request with JSON body.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check(\n\u001b[0;32m--> 625\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJson\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__customConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:959\u001b[0m, in \u001b[0;36mRequester.requestJson\u001b[0;34m(self, verb, url, parameters, headers, input, cnx, follow_302_redirect)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 959\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestEncode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m status, responseHeaders, output\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1098\u001b[0m, in \u001b[0;36mRequester.__requestEncode\u001b[0;34m(self, cnx, verb, url, parameters, requestHeaders, input, encode, stream, follow_302_redirect)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     requestHeaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m], encoded_input \u001b[38;5;241m=\u001b[39m encode(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNEW_DEBUG_FRAME(requestHeaders)\n\u001b[0;32m-> 1098\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestRaw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining \u001b[38;5;129;01min\u001b[39;00m responseHeaders \u001b[38;5;129;01mand\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit \u001b[38;5;129;01min\u001b[39;00m responseHeaders:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;66;03m# ints expected but sometimes floats returned: https://github.com/PyGithub/PyGithub/pull/2697\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining])),\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit])),\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1129\u001b[0m, in \u001b[0;36mRequester.__requestRaw\u001b[0;34m(self, cnx, verb, url, requestHeaders, input, stream, follow_302_redirect)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__requestRaw\u001b[39m(\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1121\u001b[0m     cnx: Optional[Union[HTTPRequestsConnectionClass, HTTPSRequestsConnectionClass]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     follow_302_redirect: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1128\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any], Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]:\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__deferRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         original_cnx \u001b[38;5;241m=\u001b[39m cnx\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1215\u001b[0m, in \u001b[0;36mRequester.__deferRequest\u001b[0;34m(self, verb)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msleeping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms before next GitHub request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1215\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(defer)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Create instance of GithubScraper\n",
    "gs = GithubScraper(\n",
    "    users_already_scraped=users_already_scraped,\n",
    "    companies_already_scraped=companies_already_scraped,\n",
    "    repo_limit=100\n",
    ")\n",
    "print(f'GitHub REST API ratelimit reset time for token is {gs.reset_time_point}. '\n",
    "      f'That will be in a little less than {gs.reset_time_in_minutes} minutes.')\n",
    "\n",
    "# 2. Define output file name\n",
    "file_name = 'first_tier_userinfo'\n",
    "\n",
    "# 3. Loop through company queries\n",
    "for search_query, skip_location_filter, company_label in tqdm(company_location_filter_bool_zip, total=len(second_tier_companies)):\n",
    "\n",
    "    # 3.1 Skip company if already scraped\n",
    "    if company_label in gs.companies_already_scraped:\n",
    "        print(f'[INFO] Company {company_label} already scraped. Skipping.')\n",
    "        continue\n",
    "\n",
    "    print(f'[INFO] Scraping users for company: {company_label}')\n",
    "    \n",
    "    # 3.2 Get users for this company\n",
    "    users = gs.get_gh_users(search_query, skip_location_filter)\n",
    "\n",
    "    # 3.3 Loop through users\n",
    "    for named_user, company in users:\n",
    "\n",
    "        # 3.3.1 Skip user if already scraped\n",
    "        if named_user.login in gs.users_already_scraped:\n",
    "            print(f'[INFO] User {named_user.login} already scraped. Skipping.')\n",
    "            continue\n",
    "\n",
    "        print(f'[INFO] Scraping user: {named_user.login}')\n",
    "        gs.users_already_scraped.add(named_user.login)\n",
    "\n",
    "        # 3.3.2 Get user info (may return None if repo limit exceeded or no match)\n",
    "        user_row = gs.get_user_info(named_user, company_label, company_filter=True)\n",
    "        if user_row is None:\n",
    "            continue  # Skip user if they don't meet scraping criteria\n",
    "\n",
    "        # 3.3.3 Extract match data\n",
    "        location_match = user_row.matched_location\n",
    "        inferred_company = user_row.inferred_company\n",
    "        matched_company_strings = user_row.matched_company_strings\n",
    "\n",
    "        # 3.3.4 Save user info and log result\n",
    "        gs.save_file(user_row, file_name, remove_existing_file=True)\n",
    "        gs.log_user_w_match(named_user.login, inferred_company, matched_company_strings, location_match, user_log_path) # type: ignore\n",
    "        \n",
    "        print(f'[INFO] {gs.USERS_SCRAPED} users scraped so far.')\n",
    "\n",
    "    # 3.4 Log company after scraping all users\n",
    "    gs.log_company(company_label, company_log_path) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31362c05",
   "metadata": {},
   "source": [
    "# 3 Adding new first-tier users to first-tier dataset\n",
    "\n",
    "*Note: Done by repeating notebook \"2. Creating first-tier dataset.ipynb\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee51b90",
   "metadata": {},
   "source": [
    "## 3.1 Opening the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db3f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "first_tier_file_name = \"first_tier_userinfo.jsonl\"\n",
    "fp_first_tier = fp_output_external / first_tier_file_name\n",
    "\n",
    "# Load the first tier data\n",
    "with open(fp_first_tier, \"r\") as f:\n",
    "    first_tier_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "first_tier_userinfo = pd.DataFrame(first_tier_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c15ef95",
   "metadata": {},
   "source": [
    "## 3.2 Aggegating unique user connections for each first-tier user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65f940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_ties_columns = [\n",
    "    \"follows_in\", \"follows_out\", \"watches_in\", \"watches_out\",\n",
    "    \"stars_in\", \"stars_out\", \"forks_in\", \"forks_out\",\n",
    "]\n",
    "\n",
    "first_tier_userinfo[\"unique_ties\"] = first_tier_userinfo.apply(\n",
    "    lambda row: filter_ties(row, fetch_ties_columns),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70e5cb",
   "metadata": {},
   "source": [
    "## 3.3 Save the sorted DataFrame to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec06fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users in dataset: 14\n"
     ]
    }
   ],
   "source": [
    "# Print number of users\n",
    "print(f\"Number of unique users in dataset: {len(first_tier_userinfo)}\")\n",
    "\n",
    "# Outputting sorted first-tier-user list with gzip (because of list within the dataframe)\n",
    "first_tier_userinfo.to_parquet(\n",
    "    fp_output_external / \"first_tier_ties_extended.parquet.gzip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a8a45",
   "metadata": {},
   "source": [
    "# 4 Repeating second-tier collection \n",
    "\n",
    "*Note: Done by repeating notebook \"2. Scraping second-tier users.ipynb\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8d6b9",
   "metadata": {},
   "source": [
    "## 4.1 Load in first-tier users extended version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ddbd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tier_extended_info = pd.read_parquet(fp_output_external / 'first_tier_ties_extended.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081df258",
   "metadata": {},
   "source": [
    "## 4.2 Creating a dataframe where a row is a company with a list of potential second tier users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "454b4024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n"
     ]
    }
   ],
   "source": [
    "# Aggregate potential second users for each company in the second tier\n",
    "second_tier_extended_users_and_company = (\n",
    "    first_tier_extended_info.groupby('search_with_company', as_index=False)['unique_ties']\n",
    "    .agg(lambda x: list(chain.from_iterable(x)))\n",
    ")\n",
    "\n",
    "# Calculate total number of potential second-tier users\n",
    "numb_of_second_tier_users = second_tier_extended_users_and_company['unique_ties'].str.len().sum()\n",
    "\n",
    "print(numb_of_second_tier_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fec58",
   "metadata": {},
   "source": [
    "## 4.3 Instantiating the GithubScraper and scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718e42ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File exists: first_tier_userinfo_user_log.jsonl\n",
      "[INFO] File exists: second_tier_userinfo_user_log.jsonl\n",
      "[INFO] File exists: users_attempted_scrape.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Initialize sets for tracking\n",
    "users_already_scraped = set()\n",
    "companies_already_scraped = set()\n",
    "users_attempted_scraped = set()\n",
    "\n",
    "# Paths\n",
    "first_tier_user_log_file = 'first_tier_userinfo_user_log.jsonl'\n",
    "second_tier_user_log_file = 'second_tier_userinfo_user_log.jsonl'\n",
    "users_attempted_scrape_file = 'users_attempted_scrape.jsonl'\n",
    "\n",
    "first_tier_user_log_path = fp_output_external / first_tier_user_log_file\n",
    "second_tier_user_log_path = fp_output_external / second_tier_user_log_file\n",
    "users_attempted_scrape_path = fp_output_external / users_attempted_scrape_file\n",
    "\n",
    "def ensure_file_exists(path: Path):\n",
    "    if not path.exists():\n",
    "        print(f\"[INFO] File does not exist. Creating: {path.name}\")\n",
    "        path.touch(exist_ok=True)\n",
    "    else:\n",
    "        print(f\"[INFO] File exists: {path.name}\")\n",
    "\n",
    "def load_users_from_log(path: Path):\n",
    "    users = set()\n",
    "    if path.exists():\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    user_info = json.loads(line)\n",
    "                    users.add(user_info[\"user_login\"])\n",
    "                except (json.JSONDecodeError, KeyError) as err:\n",
    "                    print(f\"[WARNING] Skipping malformed user line in {path.name}: {err}\")\n",
    "    return users\n",
    "\n",
    "# Ensure all files exist\n",
    "for path in [first_tier_user_log_path, second_tier_user_log_path, users_attempted_scrape_path]:\n",
    "    ensure_file_exists(path)\n",
    "\n",
    "# Populate sets\n",
    "users_already_scraped |= load_users_from_log(first_tier_user_log_path)\n",
    "users_already_scraped |= load_users_from_log(second_tier_user_log_path)\n",
    "users_already_attempted = load_users_from_log(users_attempted_scrape_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9651e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GithubScraper initialized with 0 companies and 3 users already scraped.\n",
      "GitHub REST API ratelimit reset time for token is 2025-08-12 14:39:58. That will be in a little less than 7 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/483 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User karuncs already scraped. Skipping.\n",
      "[NEW] GitHub ratelimit threshold set to 300 (max rate: 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/483 [00:06<55:40,  6.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 3.5 Check if user is a relevant user (DK + company)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m user_row \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamed_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_with_company\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip user if they don't meet scraping criteria\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:122\u001b[0m, in \u001b[0;36mratelimiter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Reset time passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(wait_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms ago, skipping sleep.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:701\u001b[0m, in \u001b[0;36mGithubScraper.get_user_info\u001b[0;34m(self, user, company_label, company_filter)\u001b[0m\n\u001b[1;32m    699\u001b[0m follows_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_follows_out(user)\n\u001b[1;32m    700\u001b[0m watches_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_watches_in(all_repos, user)\n\u001b[0;32m--> 701\u001b[0m watches_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_watches_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m stars_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_stars_in(all_repos, user)\n\u001b[1;32m    703\u001b[0m stars_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_stars_out(user)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:122\u001b[0m, in \u001b[0;36mratelimiter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Reset time passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(wait_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms ago, skipping sleep.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:592\u001b[0m, in \u001b[0;36mGithubScraper.get_watches_out\u001b[0;34m(self, user)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03mGet the users who are watching the specified repositories.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    List[Dict[str, str]]: A list of dictionaries containing watching information.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepo_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mowner_login\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_subscriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[get_watch_out] Failed for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;241m.\u001b[39mlogin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCopenhagen/2. SODAS/99 Asger old notebooks/Attention network/GH scrape for real 3/resources/github_functions.py:592\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03mGet the users who are watching the specified repositories.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    List[Dict[str, str]]: A list of dictionaries containing watching information.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepo_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mowner_login\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_subscriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[get_watch_out] Failed for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;241m.\u001b[39mlogin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/PaginatedList.py:84\u001b[0m, in \u001b[0;36mPaginatedListBase.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__elements\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_couldGrow():\n\u001b[0;32m---> 84\u001b[0m     newElements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m newElements\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/PaginatedList.py:95\u001b[0m, in \u001b[0;36mPaginatedListBase._grow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_grow\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T]:\n\u001b[0;32m---> 95\u001b[0m     newElements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetchNextPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__elements \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m newElements\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m newElements\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/PaginatedList.py:320\u001b[0m, in \u001b[0;36mPaginatedList._fetchNextPage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fetchNextPage\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T]:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_rest:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# REST API pagination\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         headers, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJsonAndCheck\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nextUrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nextParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m         data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getPage(data, headers)\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:625\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input, follow_302_redirect)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequestJsonAndCheck\u001b[39m(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    608\u001b[0m     verb: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     follow_302_redirect: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    Send a request with JSON body.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check(\n\u001b[0;32m--> 625\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJson\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__customConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:959\u001b[0m, in \u001b[0;36mRequester.requestJson\u001b[0;34m(self, verb, url, parameters, headers, input, cnx, follow_302_redirect)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 959\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestEncode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m status, responseHeaders, output\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1098\u001b[0m, in \u001b[0;36mRequester.__requestEncode\u001b[0;34m(self, cnx, verb, url, parameters, requestHeaders, input, encode, stream, follow_302_redirect)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     requestHeaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m], encoded_input \u001b[38;5;241m=\u001b[39m encode(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNEW_DEBUG_FRAME(requestHeaders)\n\u001b[0;32m-> 1098\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestRaw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_302_redirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_302_redirect\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining \u001b[38;5;129;01min\u001b[39;00m responseHeaders \u001b[38;5;129;01mand\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit \u001b[38;5;129;01min\u001b[39;00m responseHeaders:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;66;03m# ints expected but sometimes floats returned: https://github.com/PyGithub/PyGithub/pull/2697\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining])),\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit])),\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1129\u001b[0m, in \u001b[0;36mRequester.__requestRaw\u001b[0;34m(self, cnx, verb, url, requestHeaders, input, stream, follow_302_redirect)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__requestRaw\u001b[39m(\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1121\u001b[0m     cnx: Optional[Union[HTTPRequestsConnectionClass, HTTPSRequestsConnectionClass]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     follow_302_redirect: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1128\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any], Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]:\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__deferRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         original_cnx \u001b[38;5;241m=\u001b[39m cnx\n",
      "File \u001b[0;32m~/.local/share/uv/venvs/github/lib/python3.11/site-packages/github/Requester.py:1215\u001b[0m, in \u001b[0;36mRequester.__deferRequest\u001b[0;34m(self, verb)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msleeping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms before next GitHub request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1215\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(defer)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Create instance of GithubScraper\n",
    "gs = GithubScraper(\n",
    "    users_already_scraped=users_already_scraped,\n",
    "    companies_already_scraped=companies_already_scraped,\n",
    "    users_already_attempted=users_already_attempted,\n",
    "    repo_limit=100\n",
    ")\n",
    "\n",
    "second_tier_users_to_scrape = {\n",
    "    user: row['search_with_company']\n",
    "    for _, row in second_tier_extended_users_and_company.iterrows() # type: ignore\n",
    "    for user in row['unique_ties']\n",
    "}\n",
    "\n",
    "print(f'GitHub REST API ratelimit reset time for token is {gs.reset_time_point}. '\n",
    "      f'That will be in a little less than {gs.reset_time_in_minutes} minutes.')\n",
    "\n",
    "# 2. Define output file name\n",
    "file_name = 'second_tier_userinfo'\n",
    "\n",
    "# 3. Loop through company queries\n",
    "for user, search_with_company in tqdm(second_tier_users_to_scrape.items()):\n",
    "\n",
    "    # 3.3 Check if user is already scraped\n",
    "    if user in gs.users_already_attempted:\n",
    "        print(f'[INFO] User {user} already scraped. Skipping.')\n",
    "        continue\n",
    "\n",
    "    # Log user to the set of already attempted users\n",
    "    gs.log_user_scrape_attempt(user, users_attempted_scrape_path)\n",
    "    gs.users_already_attempted.add(user)\n",
    "\n",
    "    # 3.1 Get user from the flattened dictionary\n",
    "    named_user = gs.get_user(user)\n",
    "\n",
    "    # 3.2 Check if user is None (e.g., if user is not found)\n",
    "    if named_user is None:\n",
    "        continue\n",
    "\n",
    "    # 3.5 Check if user is a relevant user (DK + company)\n",
    "    user_row = gs.get_user_info(named_user, search_with_company, company_filter=False)\n",
    "    if user_row is None:\n",
    "        continue  # Skip user if they don't meet scraping criteria\n",
    "\n",
    "    # 3.3.3 Extract match data\n",
    "    location_match = user_row.matched_location\n",
    "    inferred_company = user_row.inferred_company\n",
    "    matched_company_strings = user_row.matched_company_strings\n",
    "\n",
    "    # 3.3.4 Save user info and log result\n",
    "    gs.save_file(user_row, file_name, remove_existing_file=True)\n",
    "    gs.log_user_w_match(named_user.login, inferred_company, matched_company_strings, location_match, second_tier_user_log_path) #type: ignore\n",
    "    \n",
    "    print(f'[INFO] {gs.USERS_SCRAPED} users scraped so far.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94599d28",
   "metadata": {},
   "source": [
    "## 4.4 Save the extended second-tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1090c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of second-tier users filtered: 3\n"
     ]
    }
   ],
   "source": [
    "# Load in second-tier users\n",
    "with open(fp_output_external / \"second_tier_userinfo.jsonl\", \"r\") as f:\n",
    "    second_tier_users = [json.loads(line) for line in f]\n",
    "\n",
    "# Print number of users\n",
    "print(f\"Number of unique users in dataset: {len(second_tier_users)}\")\n",
    "\n",
    "# Outputting sorted second-tier-user list with gzip (because of list within the dataframe)\n",
    "second_tier_users.to_parquet(\n",
    "    fp_output_external / \"second_tier_ties_extended.parquet.gzip\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
